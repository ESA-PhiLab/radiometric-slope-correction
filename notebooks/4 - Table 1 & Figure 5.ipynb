{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4 - Table 1 & Figure 5.ipynb","provenance":[{"file_id":"1JKbuKT45CNGzGLAU8sA6bwT94mnfoGap","timestamp":1583397557643}],"collapsed_sections":["UxlsCtf1wxZy","HWfNKKwC6W9z","l0_YOCs3ycr8","iItiSMFf7yRG"],"toc_visible":true,"mount_file_id":"1eS-x-nPr43dnyuHIub45Dityilyx472u","authorship_tag":"ABX9TyNg//Wo2tMBCHIkNqcYPmJn"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UxlsCtf1wxZy","colab_type":"text"},"source":["# 1 - Install missing dependencies\n","\n","For the plotting of the Land Cover map we need the earthpy python package, that relies on the libspatialindex-dev lib."]},{"cell_type":"code","metadata":{"id":"fSd2goIbwybM","colab_type":"code","outputId":"0d50d165-3c3a-4d22-b244-eeadedfd643a","executionInfo":{"status":"ok","timestamp":1584011055259,"user_tz":-60,"elapsed":27073,"user":{"displayName":"Andreas Vollrath","photoUrl":"","userId":"16529617641432137889"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["!apt-get -qq install -y libspatialindex-dev\n","!pip install -q --upgrade earthpy rasterio"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Selecting previously unselected package libspatialindex4v5:amd64.\n","(Reading database ... 134448 files and directories currently installed.)\n","Preparing to unpack .../libspatialindex4v5_1.8.5-5_amd64.deb ...\n","Unpacking libspatialindex4v5:amd64 (1.8.5-5) ...\n","Selecting previously unselected package libspatialindex-c4v5:amd64.\n","Preparing to unpack .../libspatialindex-c4v5_1.8.5-5_amd64.deb ...\n","Unpacking libspatialindex-c4v5:amd64 (1.8.5-5) ...\n","Selecting previously unselected package libspatialindex-dev:amd64.\n","Preparing to unpack .../libspatialindex-dev_1.8.5-5_amd64.deb ...\n","Unpacking libspatialindex-dev:amd64 (1.8.5-5) ...\n","Setting up libspatialindex4v5:amd64 (1.8.5-5) ...\n","Setting up libspatialindex-c4v5:amd64 (1.8.5-5) ...\n","Setting up libspatialindex-dev:amd64 (1.8.5-5) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","\u001b[K     |████████████████████████████████| 1.4MB 2.8MB/s \n","\u001b[K     |████████████████████████████████| 18.1MB 217kB/s \n","\u001b[K     |████████████████████████████████| 931kB 31.6MB/s \n","\u001b[K     |████████████████████████████████| 71kB 8.7MB/s \n","\u001b[K     |████████████████████████████████| 14.7MB 46.6MB/s \n","\u001b[K     |████████████████████████████████| 10.4MB 31.9MB/s \n","\u001b[?25h  Building wheel for earthpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for Rtree (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HWfNKKwC6W9z","colab_type":"text"},"source":["# 2 - Authenticate to Google Drive "]},{"cell_type":"code","metadata":{"id":"ZD2wpYUo6al0","colab_type":"code","outputId":"baabe816-3555-42d7-a41a-33fbf80c31c6","executionInfo":{"status":"ok","timestamp":1584011055263,"user_tz":-60,"elapsed":27066,"user":{"displayName":"Andreas Vollrath","photoUrl":"","userId":"16529617641432137889"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AtbO6VCjyQYT","colab_type":"text"},"source":["# 3 - Import necessary python libraries and mount google drive"]},{"cell_type":"code","metadata":{"id":"6BgiAXiUySOs","colab_type":"code","colab":{}},"source":["import os\n","import itertools\n","\n","import numpy as np\n","import pandas as pd \n","from scipy import stats\n","from scipy import optimize\n","\n","import rasterio as rio\n","from rasterio.windows import Window\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import earthpy.plot as ep\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l0_YOCs3ycr8","colab_type":"text"},"source":["# 4 - Read the data\n","\n","We read all bands into a dictionary, that hold the band names as key and the respective array as value. All data is cut to the same extent of 3000 x 3000 pixels.\n"]},{"cell_type":"code","metadata":{"id":"VTEKM564yXm5","colab_type":"code","outputId":"29535bd8-6df9-4c9d-e19b-2a266a8313c2","executionInfo":{"status":"ok","timestamp":1584011130903,"user_tz":-60,"elapsed":29977,"user":{"displayName":"Andreas Vollrath","photoUrl":"","userId":"16529617641432137889"}},"colab":{"base_uri":"https://localhost:8080/","height":697}},"source":["list_of_layers = [\n","    'VV_gamma0', 'VH_gamma0',\n","    'VV_gamma0flat', 'VH_gamma0flat',\n","    'alpha_rRad', 'theta_liaRad', 'aspect', \n","    'layover', 'shadow',     \n","    'landcover']\n","\n","# paths to dem and model types\n","dem = 'SRTMGL1_003'\n","models = ['volume', 'surface']\n","buffers = [0]\n","\n","modelDict = {}\n","\n","# loop thorugh all combinations and put into dictionary\n","for model, buffer in itertools.product(models, buffers):\n","\n","    key = '{}_{}_buf_{}'.format(dem, model, buffer)\n","    # here we read all layers into a dictionary\n","    dataDict = {}\n","    for layer in list_of_layers:\n","        with rio.open('/content/drive/My Drive/slope_correction {}/{}.tif'.format(key, layer)) as src:\n","            print('Reading ' + layer)\n","            dataDict[layer] = np.nan_to_num(src.read(window=Window(0, 340, 3000, 3000)))[0]\n","            print(dataDict[layer].shape)\n","    \n","    # write respective dataDict to our model dict, where different models are stored\n","    modelDict[key] = dataDict"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Reading VV_gamma0\n","(3000, 3000)\n","Reading VH_gamma0\n","(3000, 3000)\n","Reading VV_gamma0flat\n","(3000, 3000)\n","Reading VH_gamma0flat\n","(3000, 3000)\n","Reading alpha_rRad\n","(3000, 3000)\n","Reading theta_liaRad\n","(3000, 3000)\n","Reading aspect\n","(3000, 3000)\n","Reading layover\n","(3000, 3000)\n","Reading shadow\n","(3000, 3000)\n","Reading landcover\n","(3000, 3000)\n","Reading VV_gamma0\n","(3000, 3000)\n","Reading VH_gamma0\n","(3000, 3000)\n","Reading VV_gamma0flat\n","(3000, 3000)\n","Reading VH_gamma0flat\n","(3000, 3000)\n","Reading alpha_rRad\n","(3000, 3000)\n","Reading theta_liaRad\n","(3000, 3000)\n","Reading aspect\n","(3000, 3000)\n","Reading layover\n","(3000, 3000)\n","Reading shadow\n","(3000, 3000)\n","Reading landcover\n","(3000, 3000)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ngKfW11t6PSg","colab_type":"text"},"source":["# 5 - Plotting functions"]},{"cell_type":"markdown","metadata":{"id":"G0URo63k9FtB","colab_type":"text"},"source":["## 5.1 - plot aspect against backscatter function"]},{"cell_type":"code","metadata":{"id":"yjyXLoafyo8q","colab_type":"code","colab":{}},"source":["def create_plot_aspect_against_backscatter(model, data, array, mask, stats_dict, outfile, gridsize):\n","    \n","    # getlayer info #\n","    polarisation = layer.split('_')[0]\n","    flat = layer.split('_')[1][-4:]\n","    if flat != 'flat':\n","        flat = False\n","    \n","    # fore and backslope lines\n","    look_angle = 82.30213964392819 # hardcoded, \n","    backslope = look_angle\n","    foreslope = backslope + 180\n","    vertical_y = np.linspace(-28, 8, 5)\n","    fs_x = 0 * vertical_y + foreslope\n","    bs_x = 0 * vertical_y + backslope\n","    \n","    # calculate mean line\n","    horizontal_x = np.linspace(0, 360, 10) \n","    mean_y = 0 * horizontal_x + stats_dict['mean']\n","    \n","    if not flat:\n","        y_label = r'$\\gamma^0$ [dB]'\n","    else:\n","        y_label = r'$\\gamma^0_f$ [dB]'\n","    \n","    # check for 0s in aspect and update mask\n","    data['aspect'][data['aspect'] == 0] = np.nan\n","    mask = mask & np.isfinite(data['aspect'])\n","    aspect_deg_masked = np.subtract(to_deg(data['aspect'][mask]), 180)\n","    aspect_deg_masked = to_deg(data['aspect'][mask])\n","\n","    # plot\n","    # surpress plotting, since we only want to save the files\n","    plt.ioff()\n","    X = sns.jointplot(aspect_deg_masked, array[mask], kind='hex', gridsize=(gridsize, gridsize))\n","    X.ax_joint.plot(horizontal_x, mean_y, 'k--', linewidth=.75)\n","    X.ax_joint.plot(fs_x, vertical_y, 'k--', linewidth=.75)\n","    X.ax_joint.plot(bs_x, vertical_y, 'k--', linewidth=.75)\n","    X.ax_joint.set_xlabel(r'Aspect angle $\\phi_s$ [deg]', fontsize=14)\n","    X.ax_joint.set_ylabel(y_label,  fontsize=14)\n","    X.ax_joint.set_ylim(-30, 10)\n","    #X.ax_joint.set_xlim(-190, 185)\n","    X.ax_joint.set_xlim(-10, 365)\n","    \n","    # add textbox with ampl, mean and sd\n","    props = dict(boxstyle='round', facecolor='lightgrey', alpha=0.5)\n","    textstr = '\\n'.join((\n","        r'$\\mathrm{A}=%.2f$' % (stats_dict['amplitude'], ),\n","        r'$\\mu=%.2f$' % (stats_dict['mean'], ),\n","        r'$\\sigma=%.2f$' % (stats_dict['sd'], )))\n","    X.ax_joint.text(290, -28,textstr, fontsize=10, bbox=props)\n","    \n","    # add title\n","    if not flat:\n","        title = '{} Backscatter modulation by slopes'.format(polarisation)\n","    else:\n","        title = '{} Backscatter after Model {}'.format(polarisation, model)\n","        \n","    plt.suptitle(title, x=0.45, y=1.02, fontweight='bold', fontsize=14)\n","    \n","    # save\n","    plt.savefig(outfile, bbox_inches='tight', pad_inches=0.5)\n","    plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tQxejHE09RmS","colab_type":"text"},"source":["## 5.2 - plot slope steepness against backscatter function"]},{"cell_type":"code","metadata":{"id":"Lvts98T89R2y","colab_type":"code","colab":{}},"source":["def create_plot_alpha_against_backscatter(model, data, array, mask, stats_dict, outfile, gridsize):\n","    \n","    # getlayer info #\n","    polarisation = layer.split('_')[0]\n","    flat = layer.split('_')[1][-4:]\n","    if flat != 'flat':\n","        flat = False\n","    \n","    # calculate mean line\n","    horizontal_x = np.linspace(-40, 40, 10) \n","    mean_y = 0 * horizontal_x + stats_dict['mean']\n","    \n","    if not flat:\n","        y_label = r'$\\gamma^0$ [dB]'\n","    else:\n","        y_label = r'$\\gamma^0_f$ [dB]'\n","    \n","    # check for 0s in aspect and update mask\n","    data['alpha_rRad'][data['alpha_rRad'] == 0] = np.nan\n","    mask = mask & np.isfinite(data['alpha_rRad'])\n","    alpha_deg_masked = to_deg(data['alpha_rRad'][mask])\n","\n","    # plot\n","    # surpress plotting, since we only want to save the files\n","    plt.ioff()\n","    X = sns.jointplot(alpha_deg_masked, array[mask], kind='hex', gridsize=(gridsize, gridsize))\n","    X.ax_joint.plot(horizontal_x, mean_y, 'k--', linewidth=.75)\n","    X.ax_joint.set_xlabel(r'Slope Steepness in range $\\alpha$ [deg]', fontsize=14)\n","    X.ax_joint.set_ylabel(y_label, fontsize=14)\n","    X.ax_joint.set_ylim(-30, 10)\n","    X.ax_joint.set_xlim(-45, 45)\n","    \n","    # add textbox with ampl, mean and sd\n","    props = dict(boxstyle='round', facecolor='lightgrey', alpha=0.5)\n","    textstr = '\\n'.join((\n","        r'$\\mathrm{s}=%.2f$' % (stats_dict['slope'], ),\n","        r'$\\mu=%.2f$' % (stats_dict['mean'], ),\n","        r'$\\sigma=%.2f$' % (stats_dict['sd'], )))\n","    X.ax_joint.text(20, -28,textstr, fontsize=10, bbox=props)\n","    \n","    # add title\n","    if not flat:\n","        title = '{} Backscatter modulation by slopes'.format(polarisation)\n","    else:\n","        title = '{} Backscatter after Model {}'.format(polarisation, model)\n","        \n","    plt.suptitle(title, x=0.45, y=1.02, fontweight='bold', fontsize=14)\n","    \n","    # save\n","    plt.savefig(outfile, bbox_inches='tight', pad_inches=0.5)\n","    plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pg0qQvwG9i0g","colab_type":"text"},"source":["## 5.3 - plot lia against backscatter function"]},{"cell_type":"code","metadata":{"id":"OaJVHtQW9i9l","colab_type":"code","colab":{}},"source":["def create_plot_lia_against_backscatter(model, data, array, mask, stats_dict, outfile, gridsize):\n","    \n","    \n","    # getlayer info #\n","    polarisation = layer.split('_')[0]\n","    flat = layer.split('_')[1][-4:]\n","    if flat != 'flat':\n","        flat = False\n","    \n","    # calculate mean line\n","    horizontal_x = np.linspace(0, 90, 10) \n","    mean_y = 0 * horizontal_x + stats_dict['mean']\n","    \n","    if not flat:\n","        y_label = r'$\\gamma^0$ [dB]'\n","    else:\n","        y_label = r'$\\gamma^0_f$ [dB]'\n","    \n","    # check for 0s in aspect and update mask\n","    data['theta_liaRad'][data['theta_liaRad'] == 0] = np.nan\n","    mask = mask & np.isfinite(data['theta_liaRad'])\n","    theta_deg_masked = to_deg(data['theta_liaRad'][mask])\n","\n","    # plot\n","    # surpress plotting, since we only want to save the files\n","    plt.ioff()\n","    X = sns.jointplot(theta_deg_masked, array[mask], kind='hex', gridsize=(gridsize, gridsize))\n","    X.ax_joint.plot(horizontal_x, mean_y, 'k--', linewidth=.75)\n","    X.ax_joint.set_xlabel(r'Local Incidence Angle $\\theta$ [deg]', fontsize=14)\n","    X.ax_joint.set_ylabel(y_label, fontsize=14)\n","    X.ax_joint.set_ylim(-30, 10)\n","    X.ax_joint.set_xlim(-10, 100)\n","    \n","    # add textbox with ampl, mean and sd\n","    props = dict(boxstyle='round', facecolor='lightgrey', alpha=0.5)\n","    textstr = '\\n'.join((\n","        #r'$\\mathrm{s}=%.2f$' % (stats_dict['slope'], ),\n","        r'$\\mu=%.2f$' % (stats_dict['mean'], ),\n","        r'$\\sigma=%.2f$' % (stats_dict['sd'], )))\n","    X.ax_joint.text(-5, -28,textstr, fontsize=10, bbox=props)\n","    \n","    # add title\n","    if not flat:\n","        title = '{} Backscatter modulation by slopes'.format(polarisation)\n","    else:\n","        title = '{} Backscatter after Model {}'.format(polarisation, model)\n","        \n","    plt.suptitle(title, x=0.45, y=1.02, fontweight='bold', fontsize=14)\n","    \n","    # save\n","    plt.savefig(outfile, bbox_inches='tight', pad_inches=0.5)\n","    plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iItiSMFf7yRG","colab_type":"text"},"source":["# 6 - Statistics functions"]},{"cell_type":"code","metadata":{"id":"Y9cQYDg8znMo","colab_type":"code","colab":{}},"source":["# from rad to degree\n","def to_deg(rad):\n","    return np.multiply(rad,  np.divide(180,np.pi))\n","\n","# sin function or curve fitting\n","def sin_func(x, a, b, c):\n","    return a * np.sin(x + b) - c\n","\n","def tf_stats(data, array, layer, lc_class, mask):\n","    \n","    #------------------------------------------------\n","    # slope calculation\n","    \n","    # mask alpha angle\n","    data['alpha_rRad'][data['alpha_rRad'] == 0] = np.nan\n","    mask_alpha = mask & np.isfinite(data['alpha_rRad'])\n","    alpha_deg_masked = np.subtract(to_deg(data['alpha_rRad'][mask_alpha]), 180)\n","    \n","    # mask out nans\n","    x = array.copy()\n","    x[~mask_alpha] = np.nan\n","    x = x[np.logical_not(np.isnan(x))] \n","    y = alpha_deg_masked\n","    y = y[np.logical_not(np.isnan(y))]\n","    \n","    # lin-regression\n","    slope, intercept, r_value, p_value, std_err = stats.linregress(y, x)        \n","    #------------------------------------------------\n","    \n","    #------------------------------------------------\n","    # amplitude calculation\n","    \n","    # mask aspect 0s and nans\n","    data['aspect'][data['aspect'] == 0] = np.nan\n","    mask_aspect = mask & np.isfinite(data['aspect'])\n","    aspect_deg_masked = np.subtract(data['aspect'][mask_aspect], np.pi)\n","    \n","    # mask out nans\n","    x = array.copy()\n","    x[~mask_aspect] = np.nan\n","    x = x[np.logical_not(np.isnan(x))]\n","    y = aspect_deg_masked\n","    y = y[np.logical_not(np.isnan(y))]\n","   \n","    # curve fitting\n","    params, params_covariance = optimize.curve_fit(sin_func, y, x)\n","    amp = params[0]\n","    #------------------------------------------------\n","\n","    # mean, sd\n","    mean = np.nanmean(array[mask_alpha])\n","    std = np.nanstd(array[mask_alpha])\n","    \n","    # create final dictionary\n","    stat_dict = {'lc_class': lc_class, \n","                 'layer': layer, \n","                 'count': np.sum(mask), \n","                 'mean': mean, \n","                 'sd': std, \n","                 'slope': slope, \n","                 'amplitude': np.abs(amp)\n","                }\n","    \n","    return stat_dict"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0iuOOizd-n_S","colab_type":"text"},"source":["# 7 - Create figures and statistics dataframe or each model and land cover class"]},{"cell_type":"code","metadata":{"id":"UhxhmzM71IBf","colab_type":"code","outputId":"11b22ce6-83f9-4279-fe79-f88de862b67e","executionInfo":{"status":"ok","timestamp":1584012005488,"user_tz":-60,"elapsed":625556,"user":{"displayName":"Andreas Vollrath","photoUrl":"","userId":"16529617641432137889"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["# class names\n","legend_entries = [\"Build-up\", \"Flat sealed surfaces\", \"Permament soil\", \"Bare rock and screes\", \n","                  \"Water\", \"Snow and ice\", \"Trees - broad-leaved\", \"Tree - coniferous\", \"Bushes and shrubs\", \"Herbacous periodically\",\n","                  \"Herbacous permanent - low productivity\", \"Herbacous permanent - high productivity\", \"Reeds\"]\n","# class values\n","ras_values = [11, 12, 31, 32, 60, 70, 91, 93, 100, 122, 125, 126, 130]\n","\n","# reduced list of class names\n","legend_entries = [\"Bare rock and screes\", \"Trees - broad-leaved\", \n","                  \"Tree - coniferous\", \"Bushes and shrubs\", \n","                  \"Herbacous periodically\", \n","                  \"Herbacous permanent - high productivity\", \"Reeds\"]\n","# redued list of class values\n","ras_values = [32, 91, 93, 100, 122,  126, 130]\n","\n","# prepare columns for new dataframe\n","df_cols = ['lc_class', 'layer', 'count', 'mean', 'sd', 'slope', 'amplitude']\n","\n","# paths to dem and model types and buffer\n","dem = 'SRTMGL1_003'\n","models = ['surface', 'volume']\n","buffers = [0] \n","\n","# loop through different models and buffers\n","for model, buffer in itertools.product(models, buffers):\n","    \n","    # get respective arrays within the model/datadict\n","    key = '{}_{}_buf_{}'.format(dem, model, buffer)\n","    dataDict = modelDict[key]\n","    \n","    print(' INFO: Creating figures and stats for {} {} with buffer {}.'\n","      .format(dem, model, buffer)\n","    )\n","    # create empty dataframe for statistics\n","    df_stats = pd.DataFrame(columns=df_cols)\n","    \n","    # crate outdirectory where plots and stats will be saved\n","    outdir = '/content/drive/My Drive/slope_correction/pictures/{}/'.format(key)\n","    os.makedirs(outdir, exist_ok=True)\n","    \n","    # loop through classes and respective raster values file\n","    for legend_entry, ras_value in zip(legend_entries, ras_values):\n","        \n","        # set raster value respective to class\n","        print(' INFO: Analysing {} with raster value {}.'\n","          .format(legend_entry, ras_value)\n","        )\n","\n","        # loop thorugh different corrected and uncorrected layers\n","        for layer in ['VV_gamma0', 'VV_gamma0flat', 'VH_gamma0', 'VH_gamma0flat']:\n","                        \n","            # create combined Land Cover and Layover/Shadow mask\n","            valid_data_mask = (\n","                [dataDict['landcover'] == ras_value] & \n","                (dataDict['layover'] > 0) & \n","                (dataDict['shadow'] > 0)\n","            )[0] \n","\n","            # apply this mask and add valid data mask of backscatter array \n","            array = dataDict[layer].copy()\n","            array[array == 0] = np.nan\n","            mask = valid_data_mask & np.isfinite(array)\n","\n","            # set everything else to nan\n","            array[~mask] = np.nan\n","\n","            # for some classes array might be empty, so we add an if\n","            if True in np.unique(np.isfinite(array)):\n","                \n","                # calculate stats\n","                stats_dict = tf_stats(\n","                    dataDict.copy(), array, layer, legend_entry, mask\n","                )\n","                stats_dict['lc_class_code'] =  ras_value\n","\n","                # and put into pandas dataframe\n","                df = pd.DataFrame([stats_dict], columns=stats_dict.keys())\n","                df_stats = df_stats.append(stats_dict, ignore_index=True)\n","\n","                # plotting\n","                gridsize=100\n","                model_nr = '1' if model == 'volume' else '2'\n","\n","                create_plot_aspect_against_backscatter(\n","                    model_nr, dataDict.copy(), array, mask, stats_dict, \n","                    '{}/{}_{}_vs_aspect.png'.format(outdir, legend_entry, layer), \n","                    gridsize\n","                )\n","\n","                create_plot_alpha_against_backscatter(\n","                    model_nr, dataDict.copy(), array, mask, stats_dict, \n","                    '{}/{}_{}_vs_slope.png'.format(outdir, legend_entry, layer), \n","                    gridsize\n","                )\n","\n","                create_plot_lia_against_backscatter(\n","                    model_nr, dataDict.copy(), array, mask, stats_dict, \n","                    '{}/{}_{}_vs_LIA.png'.format(outdir, legend_entry, layer), \n","                    gridsize\n","                )\n","\n","        # save the complete stas dataframe to pickle\n","        df_stats.reset_index()\n","        df_stats.to_pickle('{}/stats.pickle'.format(outdir)) "],"execution_count":12,"outputs":[{"output_type":"stream","text":[" INFO: Creating figures and stats for SRTMGL1_003 surface with buffer 0.\n"," INFO: Analysing Bare rock and screes with raster value 32.\n"," INFO: Analysing Trees - broad-leaved with raster value 91.\n"," INFO: Analysing Tree - coniferous with raster value 93.\n"," INFO: Analysing Bushes and shrubs with raster value 100.\n"," INFO: Analysing Herbacous periodically with raster value 122.\n"," INFO: Analysing Herbacous permanent - high productivity with raster value 126.\n"," INFO: Analysing Reeds with raster value 130.\n"," INFO: Creating figures and stats for SRTMGL1_003 volume with buffer 0.\n"," INFO: Analysing Bare rock and screes with raster value 32.\n"," INFO: Analysing Trees - broad-leaved with raster value 91.\n"," INFO: Analysing Tree - coniferous with raster value 93.\n"," INFO: Analysing Bushes and shrubs with raster value 100.\n"," INFO: Analysing Herbacous periodically with raster value 122.\n"," INFO: Analysing Herbacous permanent - high productivity with raster value 126.\n"," INFO: Analysing Reeds with raster value 130.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RtT_Bpg9IpYV","colab_type":"text"},"source":["# 8 - re-organise statistics dataframe for creation of Table 1"]},{"cell_type":"code","metadata":{"id":"ulDA5czHAPx9","colab_type":"code","outputId":"e50c0a2a-97b9-4b4c-c08c-64d3df8f4392","executionInfo":{"status":"ok","timestamp":1584021290792,"user_tz":-60,"elapsed":1993,"user":{"displayName":"Andreas Vollrath","photoUrl":"","userId":"16529617641432137889"}},"colab":{"base_uri":"https://localhost:8080/","height":638}},"source":["df_stats_dict = {}\n","\n","# paths to dem and model types\n","dem = 'SRTMGL1_003'\n","models = ['surface', 'volume'] \n","\n","# this is for the concatenation of VV and VH stats\n","concat_cols = ['lc_class', 'lc class code', 'VV', 'Pixel count', 'VV mean', 'VV SD', 'VV slope', 'VV amp', \n","                'VH', 'VH mean', 'VH SD', 'VH slope', 'VH amp']\n","\n","# create empty list for adding all stats within the for loop\n","df_con_merged = []\n","\n","# loop through different dems and models\n","for model in models:\n","\n","    # get respective arrays within the datadict\n","    key = '{}_{}_buf_0'.format(dem, model)\n","    \n","    # read each df into the dictionary\n","    outdir = '/content/drive/My Drive/slope_correction/pictures/{}/'.format(key)\n","    df_stats = pd.read_pickle('{}/stats.pickle'.format(outdir))\n","    \n","    # split into vv and vh\n","    df_vv = df_stats[df_stats['layer'].str.contains('VV')].reset_index().rename(columns={'layer': 'VV-pol'})\n","    df_vh = df_stats[df_stats['layer'].str.contains('VH')].reset_index().rename(columns={'layer': 'VH-pol'})\n","    \n","    # concat vv and vh columns\n","    df_con = pd.concat([df_vv, df_vh], axis=1, ignore_index=True)\n","    \n","    # rename columns\n","    df_con.columns = ['i_2', 'lc_class', 'VV', 'Pixel count', 'VV mean', 'VV SD', 'VV slope', 'VV amp', 'lc class code',\n","                      'i_3', 'lc_class_2', 'VH', 'VH count', 'VH mean', 'VH SD', 'VH slope', 'VH amp', 'lc class code_2']\n","    \n","    # subset columns\n","    df_con = df_con[['lc_class', 'lc class code', 'VV', 'Pixel count', 'VV mean', 'VV SD', 'VV slope', 'VV amp', \n","                     'VH', 'VH mean', 'VH SD', 'VH slope', 'VH amp']]\n","    \n","    # rename the layer names \n","    df_con['VV'] = df_con['VV'].str.replace('VV_gamma0flat', '{}'.format(key))\n","    df_con['VH'] = df_con['VH'].str.replace('VH_gamma0flat', '{}'.format(key))\n","    \n","    df_con['VV'] = df_con['VV'].str.replace('VV_gamma0', 'Original')\n","    df_con['VH'] = df_con['VH'].str.replace('VH_gamma0', 'Original')\n","    \n","    # merge to existent dfs\n","    df_con_merged.append(df_con)\n","\n","\n","# bring all the data together\n","appended_data = pd.concat(df_con_merged)\n","\n","# exclude marginal classes\n","appended_data = appended_data[appended_data['Pixel count'] >= 100000]\n","appended_data = appended_data[['lc_class', 'VV', 'VV mean', 'VV SD', 'VV slope', 'VV amp', 'VH mean', 'VH SD', 'VH slope', 'VH amp']]\n","\n","# rename model names\n","appended_data['VV'] = appended_data['VV'].str.replace('SRTMGL1_003_volume_buf_0', 'Model I')\n","appended_data['VV'] = appended_data['VV'].str.replace('SRTMGL1_003_surface_buf_0', 'Model II')\n","\n","# remove double entries for original data and reindex \n","appended_data.drop_duplicates(subset=['lc_class', 'VV'], keep='first', inplace=True)\n","appended_data = appended_data.set_index(['lc_class', 'VV']).sort_values(['lc_class', 'VV'], ascending=False)\n","\n","# rename model column\n","appended_data"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>VV mean</th>\n","      <th>VV SD</th>\n","      <th>VV slope</th>\n","      <th>VV amp</th>\n","      <th>VH mean</th>\n","      <th>VH SD</th>\n","      <th>VH slope</th>\n","      <th>VH amp</th>\n","    </tr>\n","    <tr>\n","      <th>lc_class</th>\n","      <th>VV</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">Trees - broad-leaved</th>\n","      <th>Original</th>\n","      <td>-8.742994</td>\n","      <td>4.160108</td>\n","      <td>0.168188</td>\n","      <td>4.158141</td>\n","      <td>-14.277222</td>\n","      <td>3.975667</td>\n","      <td>0.153365</td>\n","      <td>3.743469</td>\n","    </tr>\n","    <tr>\n","      <th>Model II</th>\n","      <td>-8.957283</td>\n","      <td>3.383095</td>\n","      <td>0.074462</td>\n","      <td>2.204567</td>\n","      <td>-14.491512</td>\n","      <td>3.272042</td>\n","      <td>0.059639</td>\n","      <td>1.807970</td>\n","    </tr>\n","    <tr>\n","      <th>Model I</th>\n","      <td>-7.897023</td>\n","      <td>3.262171</td>\n","      <td>-0.012090</td>\n","      <td>1.399351</td>\n","      <td>-13.455355</td>\n","      <td>3.232874</td>\n","      <td>-0.027625</td>\n","      <td>1.302934</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">Tree - coniferous</th>\n","      <th>Original</th>\n","      <td>-7.840942</td>\n","      <td>4.189099</td>\n","      <td>0.167712</td>\n","      <td>4.671527</td>\n","      <td>-13.440296</td>\n","      <td>3.993528</td>\n","      <td>0.155542</td>\n","      <td>4.311772</td>\n","    </tr>\n","    <tr>\n","      <th>Model II</th>\n","      <td>-8.678100</td>\n","      <td>3.135113</td>\n","      <td>0.062693</td>\n","      <td>2.249442</td>\n","      <td>-14.277454</td>\n","      <td>3.017009</td>\n","      <td>0.050523</td>\n","      <td>1.902061</td>\n","    </tr>\n","    <tr>\n","      <th>Model I</th>\n","      <td>-7.885640</td>\n","      <td>3.122831</td>\n","      <td>-0.017931</td>\n","      <td>1.463594</td>\n","      <td>-13.522104</td>\n","      <td>3.089932</td>\n","      <td>-0.031240</td>\n","      <td>1.392571</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">Herbacous permanent - high productivity</th>\n","      <th>Original</th>\n","      <td>-10.386123</td>\n","      <td>3.656659</td>\n","      <td>0.156908</td>\n","      <td>2.702054</td>\n","      <td>-16.238448</td>\n","      <td>3.448673</td>\n","      <td>0.128602</td>\n","      <td>2.236016</td>\n","    </tr>\n","    <tr>\n","      <th>Model II</th>\n","      <td>-10.667173</td>\n","      <td>3.102869</td>\n","      <td>0.059841</td>\n","      <td>1.259951</td>\n","      <td>-16.519498</td>\n","      <td>3.034807</td>\n","      <td>0.031535</td>\n","      <td>0.915310</td>\n","    </tr>\n","    <tr>\n","      <th>Model I</th>\n","      <td>-10.147956</td>\n","      <td>3.092579</td>\n","      <td>-0.018945</td>\n","      <td>0.884555</td>\n","      <td>-16.027908</td>\n","      <td>3.140095</td>\n","      <td>-0.047993</td>\n","      <td>1.102624</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">Herbacous periodically</th>\n","      <th>Original</th>\n","      <td>-8.742648</td>\n","      <td>3.261588</td>\n","      <td>0.146272</td>\n","      <td>0.965537</td>\n","      <td>-15.351343</td>\n","      <td>3.183499</td>\n","      <td>0.123743</td>\n","      <td>0.757547</td>\n","    </tr>\n","    <tr>\n","      <th>Model II</th>\n","      <td>-8.767311</td>\n","      <td>3.155259</td>\n","      <td>0.061298</td>\n","      <td>0.616723</td>\n","      <td>-15.376005</td>\n","      <td>3.083171</td>\n","      <td>0.038769</td>\n","      <td>0.289349</td>\n","    </tr>\n","    <tr>\n","      <th>Model I</th>\n","      <td>-8.621692</td>\n","      <td>3.127181</td>\n","      <td>-0.023238</td>\n","      <td>0.683983</td>\n","      <td>-15.222629</td>\n","      <td>3.097570</td>\n","      <td>-0.045715</td>\n","      <td>0.487819</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">Bushes and shrubs</th>\n","      <th>Original</th>\n","      <td>-9.406825</td>\n","      <td>4.533089</td>\n","      <td>0.163166</td>\n","      <td>4.898437</td>\n","      <td>-14.851180</td>\n","      <td>4.194351</td>\n","      <td>0.142093</td>\n","      <td>4.273665</td>\n","    </tr>\n","    <tr>\n","      <th>Model II</th>\n","      <td>-10.131575</td>\n","      <td>3.535021</td>\n","      <td>0.062191</td>\n","      <td>2.369525</td>\n","      <td>-15.575931</td>\n","      <td>3.341070</td>\n","      <td>0.041118</td>\n","      <td>1.812582</td>\n","    </tr>\n","    <tr>\n","      <th>Model I</th>\n","      <td>-8.815239</td>\n","      <td>3.931240</td>\n","      <td>-0.017615</td>\n","      <td>1.600419</td>\n","      <td>-14.418124</td>\n","      <td>3.845431</td>\n","      <td>-0.042501</td>\n","      <td>1.648927</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">Bare rock and screes</th>\n","      <th>Original</th>\n","      <td>-7.993525</td>\n","      <td>5.708022</td>\n","      <td>0.194884</td>\n","      <td>6.338563</td>\n","      <td>-14.518194</td>\n","      <td>5.389315</td>\n","      <td>0.158198</td>\n","      <td>5.180944</td>\n","    </tr>\n","    <tr>\n","      <th>Model II</th>\n","      <td>-8.512291</td>\n","      <td>4.948164</td>\n","      <td>0.101666</td>\n","      <td>3.637000</td>\n","      <td>-15.036959</td>\n","      <td>4.804853</td>\n","      <td>0.064980</td>\n","      <td>2.578791</td>\n","    </tr>\n","    <tr>\n","      <th>Model I</th>\n","      <td>-6.749642</td>\n","      <td>5.634592</td>\n","      <td>-0.004452</td>\n","      <td>2.087986</td>\n","      <td>-13.244819</td>\n","      <td>5.535036</td>\n","      <td>-0.034386</td>\n","      <td>1.685885</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    VV mean  ...    VH amp\n","lc_class                                VV                   ...          \n","Trees - broad-leaved                    Original  -8.742994  ...  3.743469\n","                                        Model II  -8.957283  ...  1.807970\n","                                        Model I   -7.897023  ...  1.302934\n","Tree - coniferous                       Original  -7.840942  ...  4.311772\n","                                        Model II  -8.678100  ...  1.902061\n","                                        Model I   -7.885640  ...  1.392571\n","Herbacous permanent - high productivity Original -10.386123  ...  2.236016\n","                                        Model II -10.667173  ...  0.915310\n","                                        Model I  -10.147956  ...  1.102624\n","Herbacous periodically                  Original  -8.742648  ...  0.757547\n","                                        Model II  -8.767311  ...  0.289349\n","                                        Model I   -8.621692  ...  0.487819\n","Bushes and shrubs                       Original  -9.406825  ...  4.273665\n","                                        Model II -10.131575  ...  1.812582\n","                                        Model I   -8.815239  ...  1.648927\n","Bare rock and screes                    Original  -7.993525  ...  5.180944\n","                                        Model II  -8.512291  ...  2.578791\n","                                        Model I   -6.749642  ...  1.685885\n","\n","[18 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"4XjtcNTPM8Wq","colab_type":"text"},"source":["# 9 - Export statistics as latex table "]},{"cell_type":"code","metadata":{"id":"UXMmF5_lM8fl","colab_type":"code","colab":{}},"source":["with open('/content/drive/My Drive/slope_correction/table_all.tex', 'w') as tf:\n","     tf.write(appended_data.to_latex(columns = ['VV mean', 'VV SD', 'VV slope', 'VV amp', 'VH mean', 'VH SD', 'VH slope', 'VH amp'], index=True, bold_rows=True, escape=True, float_format=lambda x: '%10.3f' % x))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8cW8c2ucl23v","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}